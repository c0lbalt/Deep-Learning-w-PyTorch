{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2dwvZhFUF4wd+rdhUOkWc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c0lbalt/Deep-Learning-w-PyTorch/blob/main/Convolutional_NeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "no0q-QhQXOGh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert MNIST Image Files into Tensor\n",
        "# of 4-Dimensions(# of images, Height, Width, Color Channel)\n",
        "\n",
        "transform = transforms.ToTensor()"
      ],
      "metadata": {
        "id": "7IVYWps3YgnP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Data\n",
        "train_data = datasets.MNIST(root='CNN_data', train=True, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "p1rML4nkY7Xs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Data\n",
        "test_data = datasets.MNIST(root='CNN_data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "1WtGgCP1nxt9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQDPa_bWoE24",
        "outputId": "b0f8972d-19b4-4140-a18e-13f53cbd5307"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: CNN_data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCpIH4i9oHnV",
        "outputId": "4eb17f24-b2b8-4414-9d0e-5f86844282aa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: CNN_data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a small batch size for images, in this case we will use 10.\n",
        "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=10, shuffle=False)"
      ],
      "metadata": {
        "id": "IzxpTUqDo8QF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Convolutional Neural Network\n",
        "# Here we are going to describe the convolutional layer and waht it's doing (2 Convolutional Layers)\n",
        "conv1 = nn.Conv2d(1, 6, 3, 1)\n",
        "conv2 = nn.Conv2d(6, 16, 3, 1)"
      ],
      "metadata": {
        "id": "D4adUf3MAq0a"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab 1 MNIST Image\n",
        "for i, (X_Train, y_train) in enumerate(train_data):\n",
        "    break"
      ],
      "metadata": {
        "id": "KcgbFik1BK5F"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_Train.shape"
      ],
      "metadata": {
        "id": "BmSw7T2uBRFX",
        "outputId": "e9a2fdc1-c779-43eb-a192-c010ced6ab6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = X_Train.view(1,1,28,28)"
      ],
      "metadata": {
        "id": "_Nie3b5zBpzb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Time to preform our first convolution\n",
        "x = F.relu(conv1(x)) # Rectified Linear Unit for our activation function"
      ],
      "metadata": {
        "id": "LtiZOodUBsv2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "VR2VTqFxCBsY",
        "outputId": "147323b1-8b4a-4298-b3d1-25650c09645e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 26, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass thru the pooling yaer\n",
        "x = F.max_pool2d(x,2,2) # This is a kernal of 2 and a stride of 2"
      ],
      "metadata": {
        "id": "3MDY5xNEDceb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape # 26 /2 = 13"
      ],
      "metadata": {
        "id": "Dg_EVj6BEcKx",
        "outputId": "14e1c177-79cd-4e50-ed78-42c6081d86a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 13, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = F.relu(conv2(x))"
      ],
      "metadata": {
        "id": "KV3idxGaE1R1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape # Remeber, we didn't set padding so we lose 2 pixels around the outside of the image"
      ],
      "metadata": {
        "id": "YQsmoC4ZKmbV",
        "outputId": "0a744bfe-81d0-480b-d79b-18c91d632edc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 11, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Another Pooling Layer\n",
        "x = F.max_pool2d(x,2,2)"
      ],
      "metadata": {
        "id": "HV1u3GqvK0zW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape # 11 / 2 = 5.5 this value will get rounded down, since we cannot invent data to round up"
      ],
      "metadata": {
        "id": "VBObkdt-LDWl",
        "outputId": "cc719afe-fdf9-4cdc-db33-1ae917c48c76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "((28-2) / 2 - 2) / 2"
      ],
      "metadata": {
        "id": "lB7B_EtILE0I",
        "outputId": "8640b98a-8fba-42b5-8d45-bba2ae836e6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.5"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Class\n",
        "class ConvolutionalNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1,6,3,1)\n",
        "    self.conv2 = nn.Conv2d(6,16,3,1)\n",
        "    # Fully Connected Layer\n",
        "    self.fc1 = nn.Linear(5*5*16, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = F.relu(self.conv1(X))\n",
        "    X = F.max_pool2d(X,2,2) # 2x2 kernal and stride 2\n",
        "    # Second Pass\n",
        "    X = F.relu(self.conv2(X))\n",
        "    X = F.max_pool2d(X,2,2) # 2x2 kernal and stride 2\n",
        "\n",
        "    # Re-View to flatten it out\n",
        "    X = X.view(-1, 16*5*5) # negative one so that we can vary the batch size\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    X = F.relu(self.fc1(X))\n",
        "    X = F.relu(self.fc2(X))\n",
        "    X = self.fc3(X)\n",
        "    return F.log_softmax(X, dim=1)"
      ],
      "metadata": {
        "id": "TQK1xAbGLU98"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# An instance of our Model\n",
        "torch.manual_seed(41)\n",
        "model = ConvolutionalNetwork()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCvfbdODN9Zw",
        "outputId": "13775751-db4b-48cc-be1c-ef85c3a65426"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvolutionalNetwork(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loss Function Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Smaller the Learning Rate, longer its gonna take to train."
      ],
      "metadata": {
        "id": "6jBKwuJVOXpJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# Create Variables To Tracks Things\n",
        "epochs = 5\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_correct = []\n",
        "test_correct = []\n",
        "\n",
        "# For Loop of Epochs\n",
        "for i in range(epochs):\n",
        "  trn_corr = 0\n",
        "  tst_corr = 0\n",
        "\n",
        "\n",
        "  # Train\n",
        "  for b,(X_train, y_train) in enumerate(train_loader):\n",
        "    b+=1 # start our batches at 1\n",
        "    y_pred = model(X_train) # get predicted values from the training set. Not flattened 2D\n",
        "    loss = criterion(y_pred, y_train) # how off are we? Compare the predictions to correct answers in y_train\n",
        "\n",
        "    predicted = torch.max(y_pred.data, 1)[1] # add up the number of correct predictions. Indexed off the first point\n",
        "    batch_corr = (predicted == y_train).sum() # how many we got correct from this batch. True = 1, False=0, sum those up\n",
        "    trn_corr += batch_corr # keep track as we go along in training.\n",
        "\n",
        "    # Update our parameters\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    # Print out some results\n",
        "    if b%600 == 0:\n",
        "      print(f'Epoch: {i}  Batch: {b}  Loss: {loss.item()}')\n",
        "\n",
        "  train_losses.append(loss)\n",
        "  train_correct.append(trn_corr)\n",
        "\n",
        "\n",
        "  # Test\n",
        "  with torch.no_grad(): #No gradient so we don't update our weights and biases with test data\n",
        "    for b,(X_test, y_test) in enumerate(test_loader):\n",
        "      y_val = model(X_test)\n",
        "      predicted = torch.max(y_val.data, 1)[1] # Adding up correct predictions\n",
        "      tst_corr += (predicted == y_test).sum() # T=1 F=0 and sum away\n",
        "\n",
        "\n",
        "  loss = criterion(y_val, y_test)\n",
        "  test_losses.append(loss)\n",
        "  test_correct.append(tst_corr)\n",
        "\n",
        "\n",
        "\n",
        "current_time = time.time()\n",
        "total = current_time - start_time\n",
        "print(f'Training Took: {total/60} minutes!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfTyqQrVPsXb",
        "outputId": "f8d45cb5-ee91-4bf3-8e33-d4a2d4cec7f8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0  Batch: 600  Loss: 0.1623610556125641\n",
            "Epoch: 0  Batch: 1200  Loss: 0.1502392590045929\n",
            "Epoch: 0  Batch: 1800  Loss: 0.4744560718536377\n",
            "Epoch: 0  Batch: 2400  Loss: 0.14238706231117249\n",
            "Epoch: 0  Batch: 3000  Loss: 0.007758188061416149\n",
            "Epoch: 0  Batch: 3600  Loss: 0.3836284875869751\n",
            "Epoch: 0  Batch: 4200  Loss: 0.0038223876617848873\n",
            "Epoch: 0  Batch: 4800  Loss: 0.0021286322735249996\n",
            "Epoch: 0  Batch: 5400  Loss: 0.0569545142352581\n",
            "Epoch: 0  Batch: 6000  Loss: 0.00038789428072050214\n",
            "Epoch: 1  Batch: 600  Loss: 0.005851339548826218\n",
            "Epoch: 1  Batch: 1200  Loss: 0.3855525553226471\n",
            "Epoch: 1  Batch: 1800  Loss: 0.004819948226213455\n",
            "Epoch: 1  Batch: 2400  Loss: 0.003216963727027178\n",
            "Epoch: 1  Batch: 3000  Loss: 0.0332382395863533\n",
            "Epoch: 1  Batch: 3600  Loss: 0.5372857451438904\n",
            "Epoch: 1  Batch: 4200  Loss: 0.04561494290828705\n",
            "Epoch: 1  Batch: 4800  Loss: 0.0007510822033509612\n",
            "Epoch: 1  Batch: 5400  Loss: 0.0001173773780465126\n",
            "Epoch: 1  Batch: 6000  Loss: 0.14201366901397705\n",
            "Epoch: 2  Batch: 600  Loss: 0.023733172565698624\n",
            "Epoch: 2  Batch: 1200  Loss: 0.003455493599176407\n",
            "Epoch: 2  Batch: 1800  Loss: 0.0008372392621822655\n",
            "Epoch: 2  Batch: 2400  Loss: 0.010705141350626945\n",
            "Epoch: 2  Batch: 3000  Loss: 0.008078320883214474\n",
            "Epoch: 2  Batch: 3600  Loss: 0.0011862406972795725\n",
            "Epoch: 2  Batch: 4200  Loss: 0.038080841302871704\n",
            "Epoch: 2  Batch: 4800  Loss: 0.0016068397089838982\n",
            "Epoch: 2  Batch: 5400  Loss: 0.138673797249794\n",
            "Epoch: 2  Batch: 6000  Loss: 0.2449204921722412\n",
            "Epoch: 3  Batch: 600  Loss: 0.007151054684072733\n",
            "Epoch: 3  Batch: 1200  Loss: 0.011097034439444542\n",
            "Epoch: 3  Batch: 1800  Loss: 0.0017998721450567245\n",
            "Epoch: 3  Batch: 2400  Loss: 0.0001049584461725317\n",
            "Epoch: 3  Batch: 3000  Loss: 0.0031431831885129213\n",
            "Epoch: 3  Batch: 3600  Loss: 0.003668801160529256\n",
            "Epoch: 3  Batch: 4200  Loss: 0.0037249946035444736\n",
            "Epoch: 3  Batch: 4800  Loss: 0.00015864608576521277\n",
            "Epoch: 3  Batch: 5400  Loss: 0.0796482041478157\n",
            "Epoch: 3  Batch: 6000  Loss: 0.0808732658624649\n",
            "Epoch: 4  Batch: 600  Loss: 0.014099588617682457\n",
            "Epoch: 4  Batch: 1200  Loss: 0.0382874570786953\n",
            "Epoch: 4  Batch: 1800  Loss: 0.16302265226840973\n",
            "Epoch: 4  Batch: 2400  Loss: 0.02186887338757515\n",
            "Epoch: 4  Batch: 3000  Loss: 0.0024396399967372417\n",
            "Epoch: 4  Batch: 3600  Loss: 0.0013979513896629214\n",
            "Epoch: 4  Batch: 4200  Loss: 0.000989563181065023\n",
            "Epoch: 4  Batch: 4800  Loss: 0.010317974723875523\n",
            "Epoch: 4  Batch: 5400  Loss: 0.16506639122962952\n",
            "Epoch: 4  Batch: 6000  Loss: 0.0027098222635686398\n",
            "Training Took: 4.110775502522786 minutes!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph the loss at epoch\n",
        "train_losses = [tl.item() for tl in train_losses]\n",
        "plt.plot(train_losses, label=\"Training Loss\")\n",
        "plt.plot(test_losses, label=\"Validation Loss\")\n",
        "plt.title(\"Loss at Epoch\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "oB91g-BGPvI1",
        "outputId": "905b60b0-831b-46fe-d894-419d3716d539"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'float' object has no attribute 'item'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-a7d52ceeefc9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Graph the loss at epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss at Epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-a7d52ceeefc9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Graph the loss at epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss at Epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'item'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_load_everything = DataLoader(test_data, batch_size=10000, shuffle=False)"
      ],
      "metadata": {
        "id": "MdWxd6SVSp-O"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  for X_test, y_test in test_load_everything:\n",
        "    y_val = model(X_test)\n",
        "    predicted = torch.max(y_val, 1)[1]\n",
        "    correct += (predicted == y_test).sum()"
      ],
      "metadata": {
        "id": "h9TjDFgjSuY7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Did for correct\n",
        "correct.item()/len(test_data)*100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtOE6XExSxQf",
        "outputId": "c76815b2-dde5-41c6-a670-2e6640abeb0c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.57000000000001"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab an image\n",
        "test_data[1978] # Tensor with an image in it...at end, it shows the label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTFpTOLVSzKU",
        "outputId": "7ad8f9ed-19d6-4edb-f43a-914e5805a2f5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.4392, 0.6902, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.2314,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.7922, 0.9255, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5490, 0.9843,\n",
              "           0.1608, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0353, 0.8392, 0.9255, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6196, 0.9961,\n",
              "           0.1725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.1412, 0.9961, 0.7333, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8941, 0.9059,\n",
              "           0.0824, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.3804, 0.9961, 0.5804, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8941, 0.8235,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.8275, 0.9961, 0.4196, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1098, 0.9412, 0.8235,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0314, 0.3098,\n",
              "           0.7569, 0.7922, 0.9608, 0.9961, 0.2392, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2667, 0.9961, 0.6784,\n",
              "           0.0000, 0.0000, 0.0000, 0.0039, 0.0706, 0.6392, 0.8235, 0.9961,\n",
              "           0.9961, 0.9961, 0.9961, 0.9294, 0.1412, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.7176, 0.9961, 0.3804,\n",
              "           0.2039, 0.2627, 0.3804, 0.4039, 0.9961, 1.0000, 0.9961, 0.9725,\n",
              "           0.7686, 0.9451, 0.9961, 0.4196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0863, 0.8314, 0.9961, 0.9961,\n",
              "           0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.5647, 0.1294,\n",
              "           0.0000, 0.8588, 0.9961, 0.2039, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1686, 0.7529, 0.9961,\n",
              "           0.9961, 0.9961, 0.9765, 0.6863, 0.5686, 0.0000, 0.0000, 0.0000,\n",
              "           0.1373, 0.9529, 0.9961, 0.2078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0314,\n",
              "           0.0314, 0.0314, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.3059, 0.9961, 0.9451, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.7529, 0.9961, 0.9608, 0.1569, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2196,\n",
              "           0.9843, 0.9961, 0.7843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3020,\n",
              "           0.9961, 0.9961, 0.2157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7529,\n",
              "           0.9961, 0.8510, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9294,\n",
              "           0.9961, 0.5490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.9333,\n",
              "           0.9961, 0.2196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2667, 0.9922,\n",
              "           0.9882, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9294,\n",
              "           0.4353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " 4)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab just the data\n",
        "test_data[1978][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiVZb5KvS1yD",
        "outputId": "6f906f57-4913-4c7c-c991-1831dfa870e9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.4392, 0.6902, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.2314,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.7922, 0.9255, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5490, 0.9843,\n",
              "          0.1608, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0353, 0.8392, 0.9255, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6196, 0.9961,\n",
              "          0.1725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.1412, 0.9961, 0.7333, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8941, 0.9059,\n",
              "          0.0824, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.3804, 0.9961, 0.5804, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8941, 0.8235,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.8275, 0.9961, 0.4196, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1098, 0.9412, 0.8235,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0314, 0.3098,\n",
              "          0.7569, 0.7922, 0.9608, 0.9961, 0.2392, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2667, 0.9961, 0.6784,\n",
              "          0.0000, 0.0000, 0.0000, 0.0039, 0.0706, 0.6392, 0.8235, 0.9961,\n",
              "          0.9961, 0.9961, 0.9961, 0.9294, 0.1412, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.7176, 0.9961, 0.3804,\n",
              "          0.2039, 0.2627, 0.3804, 0.4039, 0.9961, 1.0000, 0.9961, 0.9725,\n",
              "          0.7686, 0.9451, 0.9961, 0.4196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0863, 0.8314, 0.9961, 0.9961,\n",
              "          0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.5647, 0.1294,\n",
              "          0.0000, 0.8588, 0.9961, 0.2039, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1686, 0.7529, 0.9961,\n",
              "          0.9961, 0.9961, 0.9765, 0.6863, 0.5686, 0.0000, 0.0000, 0.0000,\n",
              "          0.1373, 0.9529, 0.9961, 0.2078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0314,\n",
              "          0.0314, 0.0314, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.3059, 0.9961, 0.9451, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.7529, 0.9961, 0.9608, 0.1569, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2196,\n",
              "          0.9843, 0.9961, 0.7843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3020,\n",
              "          0.9961, 0.9961, 0.2157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7529,\n",
              "          0.9961, 0.8510, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9294,\n",
              "          0.9961, 0.5490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.9333,\n",
              "          0.9961, 0.2196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2667, 0.9922,\n",
              "          0.9882, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9294,\n",
              "          0.4353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000]]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape it\n",
        "test_data[1978][0].reshape(28,28)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_AKcxbRS7WY",
        "outputId": "0f62cfe2-4253-46d0-b316-8f96fbcc8781"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.4392, 0.6902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.2314, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.7922, 0.9255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5490, 0.9843, 0.1608,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0353, 0.8392, 0.9255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6196, 0.9961, 0.1725,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.1412, 0.9961, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8941, 0.9059, 0.0824,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.3804, 0.9961, 0.5804, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8941, 0.8235, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.8275, 0.9961, 0.4196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1098, 0.9412, 0.8235, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0314, 0.3098, 0.7569, 0.7922,\n",
              "         0.9608, 0.9961, 0.2392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2667, 0.9961, 0.6784, 0.0000,\n",
              "         0.0000, 0.0000, 0.0039, 0.0706, 0.6392, 0.8235, 0.9961, 0.9961, 0.9961,\n",
              "         0.9961, 0.9294, 0.1412, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.7176, 0.9961, 0.3804, 0.2039,\n",
              "         0.2627, 0.3804, 0.4039, 0.9961, 1.0000, 0.9961, 0.9725, 0.7686, 0.9451,\n",
              "         0.9961, 0.4196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0863, 0.8314, 0.9961, 0.9961, 0.9961,\n",
              "         0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.5647, 0.1294, 0.0000, 0.8588,\n",
              "         0.9961, 0.2039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1686, 0.7529, 0.9961, 0.9961,\n",
              "         0.9961, 0.9765, 0.6863, 0.5686, 0.0000, 0.0000, 0.0000, 0.1373, 0.9529,\n",
              "         0.9961, 0.2078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0314, 0.0314,\n",
              "         0.0314, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3059, 0.9961,\n",
              "         0.9451, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7529, 0.9961,\n",
              "         0.9608, 0.1569, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2196, 0.9843, 0.9961,\n",
              "         0.7843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3020, 0.9961, 0.9961,\n",
              "         0.2157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7529, 0.9961, 0.8510,\n",
              "         0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.9961, 0.5490,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.9333, 0.9961, 0.2196,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2667, 0.9922, 0.9882, 0.1333,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.4353, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the image\n",
        "plt.imshow(test_data[1978][0].reshape(28,28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "TZ_0sLIETQ8Z",
        "outputId": "3c7c56bf-01b6-40f9-ee53-2950ccccdbc9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7b4e11bcd790>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass the image thru our model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  new_prediction = model(test_data[1978][0].view(1,1,28,28)) # batch size of 1, 1 color channel, 28x28 image"
      ],
      "metadata": {
        "id": "wRthdRUMTTTo"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the new prediction...get probabilities\n",
        "new_prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrGUBTAaTXJn",
        "outputId": "816e8c97-05ce-4d03-a536-fd4e1e2c4600"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.4992e+01, -1.8860e+01, -2.4744e+01, -3.0158e+01, -4.7684e-07,\n",
              "         -2.1318e+01, -2.2632e+01, -2.0485e+01, -2.1817e+01, -1.4484e+01]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_prediction.argmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JashP7GCTagI",
        "outputId": "12a1d321-37ac-4040-9379-f7272099ef78"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aQ_XhAXZTcWl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}